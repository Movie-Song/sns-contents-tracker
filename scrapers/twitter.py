import feedparser
from datetime import datetime
from typing import List, Dict

class TwitterScraper:
    """íŠ¸ìœ„í„°(X)ì˜ Nitter RSS í”¼ë“œë¥¼ íŒŒì‹±í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ì‘ë™ ê°€ëŠ¥í•œ ì—¬ëŸ¬ Nitter ì¸ìŠ¤í„´ìŠ¤ (ìë™ í´ë°±)
    NITTER_INSTANCES = [
        "https://nitter.privacydev.net",
        "https://nitter.net",
        "https://nitter.poast.org",
        "https://nitter.unixfox.eu",
        "https://nitter.cz",
    ]
    
    def __init__(self, username: str, nitter_instance: str = None):
        """
        Args:
            username: íŠ¸ìœ„í„° ì‚¬ìš©ìëª… (@ ì œì™¸)
            nitter_instance: Nitter ì¸ìŠ¤í„´ìŠ¤ URL (ê¸°ë³¸: ìë™ ì„ íƒ)
        """
        self.username = username.lstrip('@')
        
        # íŠ¹ì • ì¸ìŠ¤í„´ìŠ¤ê°€ ì§€ì •ë˜ë©´ ê·¸ê²ƒë§Œ ì‚¬ìš©, ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ìë™ ì„ íƒ
        if nitter_instance:
            self.nitter_instances = [nitter_instance.rstrip('/')]
        else:
            self.nitter_instances = self.NITTER_INSTANCES
        
        # ê³„ì •ëª…ì„ í¬í•¨í•œ í”Œë«í¼ ì´ë¦„ìœ¼ë¡œ êµ¬ë¶„ ê°€ëŠ¥í•˜ê²Œ ì„¤ì •
        self.platform = f"Twitter (@{self.username})"
    
    def fetch_posts(self, limit: int = 50) -> List[Dict]:
        """
        RSS í”¼ë“œì—ì„œ ìµœì‹  íŠ¸ìœ—ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        ì—¬ëŸ¬ Nitter ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.
        
        Args:
            limit: ê°€ì ¸ì˜¬ ìµœëŒ€ íŠ¸ìœ— ìˆ˜ (ê¸°ë³¸ 50ê°œ)
        
        Returns:
            List[Dict]: íŠ¸ìœ— ì •ë³´ ë¦¬ìŠ¤íŠ¸
                - title: ì œëª© (íŠ¸ìœ— ë‚´ìš©)
                - url: URL
                - published_date: ë°œí–‰ì¼ (YYYY-MM-DDTHH:MM:SS í˜•ì‹)
                - platform: í”Œë«í¼ ì´ë¦„
        """
        last_error = None
        
        # ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
        for instance in self.nitter_instances:
            rss_url = f"{instance}/{self.username}/rss"
            print(f"ğŸ” {self.platform} í”¼ë“œ í™•ì¸ ì¤‘: {rss_url}")
            
            try:
                # RSS í”¼ë“œ íŒŒì‹±
                feed = feedparser.parse(rss_url)
                
                # íŒŒì‹± ì—ëŸ¬ ì²´í¬
                if feed.bozo:
                    last_error = f"íŒŒì‹± ì˜¤ë¥˜: {feed.bozo_exception}"
                    print(f"âš ï¸  ì´ ì¸ìŠ¤í„´ìŠ¤ëŠ” ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {last_error}")
                    continue
                
                # ì—”íŠ¸ë¦¬ê°€ ì—†ëŠ” ê²½ìš°
                if not feed.entries:
                    last_error = "í”¼ë“œì— íŠ¸ìœ—ì´ ì—†ìŠµë‹ˆë‹¤"
                    print(f"âš ï¸  ì´ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ íŠ¸ìœ—ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # ì„±ê³µ! íŠ¸ìœ— íŒŒì‹±
                posts = []
                for entry in feed.entries[:limit]:
                    # ì œëª© (íŠ¸ìœ— ë‚´ìš©)
                    title = entry.get('title', 'ë‚´ìš© ì—†ìŒ')
                    
                    # URL - Nitter URLì„ Twitter URLë¡œ ë³€í™˜
                    nitter_url = entry.get('link', '')
                    twitter_url = self._convert_to_twitter_url(nitter_url, instance)
                    
                    # ë°œí–‰ì¼ íŒŒì‹±
                    published_date = self._parse_date(entry)
                    
                    if twitter_url and published_date:
                        posts.append({
                            'title': title,
                            'url': twitter_url,
                            'published_date': published_date,
                            'platform': self.platform
                        })
                
                print(f"âœ… {len(posts)}ê°œì˜ íŠ¸ìœ—ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. (ì¸ìŠ¤í„´ìŠ¤: {instance})")
                return posts
                
            except Exception as e:
                last_error = str(e)
                print(f"âš ï¸  ì¸ìŠ¤í„´ìŠ¤ ì ‘ì† ì‹¤íŒ¨: {last_error}")
                continue
        
        # ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ì‹¤íŒ¨
        print(f"âŒ ëª¨ë“  Nitter ì¸ìŠ¤í„´ìŠ¤ì—ì„œ íŠ¸ìœ—ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error}")
        print(f"   ì‹œë„í•œ ì¸ìŠ¤í„´ìŠ¤: {', '.join(self.nitter_instances)}")
        return []
    
    def _convert_to_twitter_url(self, nitter_url: str, instance: str) -> str:
        """
        Nitter URLì„ ê³µì‹ Twitter URLë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            nitter_url: Nitter URL
            instance: ì‚¬ìš©ëœ Nitter ì¸ìŠ¤í„´ìŠ¤
        
        Returns:
            str: Twitter URL
        """
        if not nitter_url:
            return ""
        
        try:
            # nitter.xxx/username/status/123 -> twitter.com/username/status/123
            parts = nitter_url.replace(instance, 'https://twitter.com')
            return parts
        except:
            return nitter_url
    
    def _parse_date(self, entry) -> str:
        """
        RSS ì—”íŠ¸ë¦¬ì—ì„œ ë‚ ì§œë¥¼ íŒŒì‹±í•˜ì—¬ YYYY-MM-DDTHH:MM:SS í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            entry: feedparser entry ê°ì²´
        
        Returns:
            str: YYYY-MM-DDTHH:MM:SS í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
        """
        # published_parsed ë˜ëŠ” updated_parsed ì‚¬ìš©
        date_tuple = entry.get('published_parsed') or entry.get('updated_parsed')
        
        if date_tuple:
            try:
                dt = datetime(*date_tuple[:6])
                return dt.strftime("%Y-%m-%dT%H:%M:%S")
            except:
                pass
        
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
        return None
    
    def get_recent_posts(self, days: int = 30) -> List[Dict]:
        """
        ìµœê·¼ Nì¼ ì´ë‚´ì˜ íŠ¸ìœ—ë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            days: ì¡°íšŒí•  ì¼ìˆ˜ (ê¸°ë³¸ 30ì¼)
        
        Returns:
            List[Dict]: ìµœê·¼ íŠ¸ìœ— ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        from datetime import timedelta
        
        all_posts = self.fetch_posts()
        cutoff_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        
        recent_posts = [
            post for post in all_posts 
            if post['published_date'] >= cutoff_date
        ]
        
        print(f"ğŸ“… ìµœê·¼ {days}ì¼ ì´ë‚´ íŠ¸ìœ—: {len(recent_posts)}ê°œ")
        return recent_posts


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    import os
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ íŠ¸ìœ„í„° ì‚¬ìš©ìëª… ê°€ì ¸ì˜¤ê¸°
    test_username = os.getenv('TWITTER_USERNAME', 'elonmusk')
    
    print("=== íŠ¸ìœ„í„° ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ===\n")
    
    scraper = TwitterScraper(test_username)
    
    # ìµœê·¼ 10ê°œ íŠ¸ìœ— ê°€ì ¸ì˜¤ê¸°
    posts = scraper.fetch_posts(limit=10)
    
    if posts:
        print(f"\nğŸ“ ìµœê·¼ íŠ¸ìœ— ëª©ë¡:")
        for i, post in enumerate(posts, 1):
            print(f"{i}. {post['title'][:80]}...")
            print(f"   URL: {post['url']}")
            print(f"   ë‚ ì§œ: {post['published_date']}\n")
    else:
        print("\nâš ï¸  íŠ¸ìœ—ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
